#summary Demonstrates the usage of code in the python-examples directory.
#labels Phase-Support

= Introduction =

Using the example code in the python-examples directory is straightforward and will allow you to pull both aggregate and entity style queries from the [http://www.recordedfuture.com/api/home/ Recorded Future API]. You'll need [http://www.python.org/ Python 2.6 (or greater)] installed in order to use these scripts. 


= Instructions =

==Get the code==

You'll need to check out the code with [http://subversion.tigris.org/ Subversion]. With the command line client, the proper way to check out the code follows.

{{{
svn checkout http://recordedfuture.googlecode.com/svn/trunk/python-examples/ recordedfuture-read-only 
}}}

A new directory called "recordedfuture-read-only" will be created in your current working directory and the python files will be included in it. Change to this directory for the remainder of these instructions.

{{{
cd recordedfuture-read-only
}}}


==Run the code==

Running the code is simple when you've got Python 2.6+ installed. We'll go over the two types of queries separately. 

===Entity Queries===
An entity style query pulls information about any occurrences of an entity from our database, subject to the constraints of the query itself. If, for instance, you only want to see occurrences published in a particular date range, you will set that in the query. By default, our program *entquery.py* is set up to pull all occurrences of a list of entities (identified by market ticker) over a user-specified date range. The list of entities is provided in a file. The file should contain tickers, one per line, for which the user wants to see entity occurrences. A sample file *tickerfile.txt* is provided in the python-examples directory.

To run the example entity style query you'll do the following:
{{{
python entquery.py MYTOKEN tickerfile.txt 20100614 20100620 > entoutputfile.txt
}}}
The fifth and sixth arguments above are the date range over which you want to run the query. Query ouput will be placed in the file *entoutputfile.txt* and you should see something like this in your terminal: 
{{{
Running ticker C
Running ticker GOOG
Running ticker MSFT
Running ticker YHOO
Running ticker CHK
Running ticker XOM
Running ticker GE
Running ticker INTC
}}}

===Aggregate Queries===
Aggregate queries are similar to entity queries. The main difference they provide is that they aggregate all occurrences on a particular date for a particular ticker and provide total counts of the types of events you query for, as well as average momentum and sentiment metrics for those instances on those days. Running is similar to the entity query, but the output will look slightly different. To run:

{{{
python aggquery.py MYTOKEN tickerfile.txt 20100614 20100620 > aggoutputfile.txt
}}}

This time you'll see the following in your terminal:
{{{
Running date 2010-06-14
Running date 2010-06-15
Running date 2010-06-16
Running date 2010-06-17
Running date 2010-06-18
Running date 2010-06-19
Running date 2010-06-20
}}}

==Examine the output==

===Entity Query Output===
Some lines of the entity query output should look something like this:
{{{
ticker	id	document.published	document.source.name	start	stop	type	momentum	positive	negative
C	990192	"2010-06-14T18:30:00.000Z	"clusterstock	"2010-06-11T00:00:00.000Z	"2010-06-11T00:00:00.000Z	"EntityOccurrence	0.0486139160644	 	 
C       2262357 "2010-06-17T09:23:20.000Z       "24_7   "2010-06-17T09:23:20.000Z       "2010-06-17T09:23:20.000Z       "CompanyTicker  0.109071484071
C       2486846 "2010-06-17T12:52:15.000Z       "seeking_alpha_usmarket "2010-06-17T12:52:15.000Z       "2010-06-17T12:52:15.000Z       "CompanyEmployeesNumber 0.268442292171
C       2506216 "2010-06-17T14:31:00.000Z       "techweb_all_feed       "2010-06-17T00:00:00.000Z       "2010-06-17T00:00:00.000Z       "CompanyLocation        0.112606948405
C       2583817 "2010-06-17T14:20:25.000Z       "capitaliqpowermoves    "2010-06-17T14:20:25.000Z       "2010-06-17T14:20:25.000Z       "PersonCareer   0.0180406149754
C       2604184 "2010-06-17T20:08:01.000Z       "pr_inside_business     "2010-06-17T20:08:01.000Z       "2010-06-17T20:08:01.000Z       "CompanyTicker  0.0894946294307
C       2604188 "2010-06-17T20:08:01.000Z       "pr_inside_business     "2010-06-17T20:08:01.000Z       "2010-06-17T20:08:01.000Z       "CompanyTicker  0.0894946294307
C       2616392 "2010-06-17T20:00:00.000Z       "marketwire     "2010-06-17T20:00:00.000Z       "2010-06-17T20:00:00.000Z       "CompanyTicker  0.120274979187
C       2618372 "2010-06-17T21:04:43.000Z       "blogtaragana   "2010-06-17T21:04:43.000Z       "2010-06-17T21:04:43.000Z       "CompanyInvestment      0.10235846086
C       2679963 "2010-06-18T07:23:06.000Z       "reuters_private_equity "2010-01-01T00:00:00.000Z       "2010-01-01T00:00:00.000Z       "CompanyInvestment      0.0649858926842
C       2688602 "2010-06-18T08:02:43.000Z       "reuters_ma     "2010-01-01T00:00:00.000Z       "2010-01-01T00:00:00.000Z       "CompanyInvestment      0.17407960199
C       2688607 "2010-06-18T08:02:43.000Z       "reuters_ma     "2010-06-18T00:00:00.000Z       "2010-06-18T00:00:00.000Z       "CompanyInvestment      0.17407960199
C       2765174 "2010-06-18T07:32:03.000Z       "economictimesindia     "2010-01-01T00:00:00.000Z       "2010-01-01T00:00:00.000Z       "CompanyInvestment      0.209822085567
....
}}}

This file is a tab-delimited file, with column headings at the top. It should be pretty straightforward to open this in Excel or read it in with R's read.delim() command. The output columns are the ticker, the document ID, the publish date for the document, the document source, the time period that the document references, the momentum of the entity and the sentiment behind the entity. Not all fields will always be published. 

===Aggregate Query Output===
Some aggregate results will look something like this:

{{{
tickers,Day,Count,Momentum,Positive,Negative
GOOG,2010-06-14,987,0.348027749091,0.07336196219,0.01466786384
INTC,2010-06-14,288,0.148892345712,0.05220133659,0.00207086951
MSFT,2010-06-14,2131,0.554405631849,0.03840043871,0.00970781516
XOM,2010-06-14,100,0.0345069934921,0.02981864773,0.08003951591
YHOO,2010-06-14,303,0.108720400113,0.06675251259,0.00468387133
...
}}}

The columns here are the ticker, date for the aggregate, count of articles referencing the entity associated with the ticker, and the average momentum and sentiment associated with the ticker on that date. In this case, results are in CSV format, again easily ingestible by your favorite statistics software.

== Modify the code ==

Users will likely want to try running their own queries, and the neat thing about the JSON query API is how flexible it is. You can query the data in the Recorded Future database from all sorts of directions. Changing dates and tickers really just scratches the surface. 

Before messing around with the queries, I recommend reading [http://www.recordedfuture.com/api/home/ our API documentation]. There you will find what type of data you can ask for and what the various metadata fields in the results mean.

To change output columns in the code, currently you need to change two lines in entquery.py. First you'll change the line
{{{
outfields = ["id","time","source.name", "document.published","type", "momentum", "sentiment"]
}}}
to match the output fields you decide on after reading the API documentation.

Next, you'll need to change the line:
{{{
outorder = ["id","document.published", "document.source.name", "start","stop","type", "momentum", "positive", "negative"]
}}}
to match the output order that matches what you'd like in your output file. Planned enhancements to the helper functions in recfut.py should eliminate the need to manually set these in multiple place, but for now this should do the trick. 