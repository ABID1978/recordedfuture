#summary Demonstrates the usage of code in the python-examples directory.
#labels Phase-Support

= Introduction =

Using the example code in the python-examples directory is straightforward and will allow you to pull both aggregate and entity style queries from the [http://code.google.com/p/recordedfuture/wiki/RecordedFutureAPI Recorded Future API]. You'll need [http://www.python.org/ Python 2.6 (or greater)] installed in order to use these scripts. You will also need a Recorded Future API token. To obtain access to a token, please e-mail [mailto:sales@recordedfuture.com sales@recordedfuture.com].


= Instructions =

==Get the code==

The easiest way to get the code is to save the following files to the same directory:
  * [http://recordedfuture.googlecode.com/svn/trunk/python-examples/pull_live/aggregatequery.rfq aggregatequery.rfq]
  * [http://recordedfuture.googlecode.com/svn/trunk/python-examples/pull_live/instancequery.rfq instancequery.rfq]
  * [http://recordedfuture.googlecode.com/svn/trunk/python-examples/pull_live/recfut.py recfut.py]
  * [http://recordedfuture.googlecode.com/svn/trunk/python-examples/pull_live/uidecode.py uidecode.py]
  * [http://recordedfuture.googlecode.com/svn/trunk/python-examples/pull_live/pull_live.py pull_live.py]
  * [http://recordedfuture.googlecode.com/svn/trunk/python-examples/pull_live/entity_lookup.py entity_lookup.py]

You can also [http://code.google.com/p/recordedfuture/source/browse/#svn/trunk/python-examples/pull_live browse for it] and view the files online for now if you'd prefer. 

Alternatively, if you have [http://subversion.tigris.org/ Subversion] installed, you can check out the code as follows:

{{{
svn checkout http://recordedfuture.googlecode.com/svn/trunk/python-examples/pull_live recordedfuture-read-only 
}}}

A new directory called "recordedfuture-read-only" will be created in your current working directory and the python files will be included in it. 

In any case, you'll want to fire up a terminal (cmd.exe on Windows, Terminal on Mac, or Xterm/gnome-terminal on Linux) and cd to the directory that houses these four files for the remainder of this tutorial. 


==Run the code==

Running the code is simple when you've got Python 2.6+ installed. We'll go over the two types of queries separately. For more options to parameterize the query, you can run:
{{{
python pull_live.py --help
}}}
or
{{{
python entity_lookup.py --help
}}}

===Entity Queries===
An entity query will look up information about entities in our system. This will help you obtain entity IDs for later queries to the system. For instance, if you want to look up the entity id for "Chevy Chase", you could run something like the following:
{{{
python entity_lookup.py -t MYTOKEN--type=Person --name="Chevy Chase"
}}}

Which yields:
{{{
Id,Name,Type,Hits,Momentum,Attributes
B_asX,Chevy Chase,Person,3950,0.0010537690652378975,birth:1943-10-08|gender:male
}}}

==Other examples==
Top 20 commodities in the system.
{{{
python entity_lookup.py -t MYTOKEN --type=Commodity --top=20
}}}

Top 50 entities with "Illinois" in the name:
{{{
python entity_lookup.py -t MYTOKEN--freetext="Illinois" --top=50
}}}

Look up the entity with the id "B_LyO" (Apple):
{{{
python entity_lookup.py -t MYTOKEN--id="B_LyO"
}}}

You can also specify types, names, or ids in a list from a file, with values one-per-line with the arguments "typefile", "namefile", and "idfile", respectively.


===Instance Queries===
An instance query pulls information about any occurrences of an entity or event from our database, subject to the constraints of the query itself. If, for instance, you only want to see instances published in a particular date range, you will set that in the query. By default, our query *instancequery.rfq* is set up to pull all occurrences of a list of entities and events (identified by an RF ID) over a user-specified date range. The list of entities is provided in the query itself, but may be provided in a separate file. That file should contain entity ids, one per line, for which the user wants to see entity occurrences and event instances. A sample file *idfile.txt* is provided in the example directory. IDs can be specified from this file with the option "-i idfile.txt".

To run the example entity style query you'll do the following:
{{{
python pull_live.py -t MYTOKEN --min 2012-08-15 --max 2012-08-20 -p instancequery.rfq > output_file.csv
}}}

MYTOKEN will be substituted with your API Token. The fifth and sixth arguments above are the date range over which you want to run the query. Query ouput will be placed in the file *output_file.csv* and you should see something like this in your terminal - this is the fully parameterized query you are executing against the API: 
{{{
{
  "instance": {
    "attributes": {
      "entity": {
        "id": "B_Ggm"
      }
    }, 
    "document": {
      "published": {
        "max": "2012-08-20", 
        "min": "2012-08-15"
      }
    }, 
    "limit": 20000
  }, 
  "token": "MYTOKEN"
}

}}}

===Aggregate Queries===
Aggregate queries are similar to entity queries. The main difference they provide is that they aggregate all occurrences on a particular date for a particular ticker and provide total counts of the types of events you query for, as well as average momentum and sentiment metrics for those instances on those days. 

Running is similar to the entity query, but the output will look slightly different. To run:

{{{
python pull_live.py -t MYTOKEN --min 2012-08-15 --max 2012-08-20 -p aggregatequery.rfq > agg_output_file.csv
}}}

You should see similar output in your terminal - reflecting only the difference in the query type.


==Examine the output==

===Entity Query Output===
Some lines of the entity query output should look something like this:
{{{
id,momentum,positive,negative,canonical.id,type,document.id,document.published,document.downloaded,start,stop,document.url,document.title,document.sourceId.id,document.sourceId.name,document.sourceId.media_type,document.sourceId.topic,document.sourceId.country,fragment,attributes
GP8HngAGiYj,0.00208338366054,0.0,0.0,GI-LKYw3RgP,CoOccurrence,JP2_CI,2012-08-17T12:30:24.000Z,2012-08-17T12:34:06.930Z,2012-08-17T12:30:24.000Z,2012-08-17T12:30:24.000Z,http://theaviationist.com/2012/08/17/gunship-releasing-flares/,Video shows Syrian Mil Mi-25 gunship releasing flares. A sign that rebels got their hands on MANPADS?,I8K-8k,The Aviationist,Blog,Geopolitical,United States of America,"Lockheed Martin, Boeing, Honeywell and Pratt & Whitney sued by F-22 pilot's widow.","entities:Pratt & Whitney,F-22,Honeywell International Inc,Boeing,Lockheed Martin||positive:0.0||general_positive:0.0||general_negative:0.47368422||negative:0.0"
GP7pV6ABCxu,0.075499758726,0.0,0.0,B_Ggm,EntityOccurrence,JPugEC,2012-08-16T02:03:38.000Z,2012-08-16T02:03:40.260Z,2011-01-01T00:00:00.000Z,2011-12-31T23:59:59.000Z,http://feeds.bizjournals.com/~r/vertical_30/~3/h2SDu6QnxXE/hypersonic-boeing-waverider-fails.html,Hypersonic Boeing Waverider fails after six seconds,C11,Bizjournals.com,Niche,,United States of America,"The Waverider is a collaboration between Boeing and Pratt & Whitney Rocketdyne, and the Air Force Research Laboratory and Defense Advanced Research Projects Agency (DARPA).","positive:0.0||negative:0.0||entity:Boeing||general_negative:0.0||inherited_locations:Huntington Beach,California,Ohio||general_positive:0.0||document_category:Disaster_Accident"
GP7pV6ABCxt,0.075499758726,0.0,0.0,B_Ggm,EntityOccurrence,JPugEC,2012-08-16T02:03:38.000Z,2012-08-16T02:03:40.260Z,2010-01-01T00:00:00.000Z,2010-12-31T23:59:59.000Z,http://feeds.bizjournals.com/~r/vertical_30/~3/h2SDu6QnxXE/hypersonic-boeing-waverider-fails.html,Hypersonic Boeing Waverider fails after six seconds,C11,Bizjournals.com,Niche,,United States of America,"The Waverider is a collaboration between Boeing and Pratt & Whitney Rocketdyne, and the Air Force Research Laboratory and Defense Advanced Research Projects Agency (DARPA).","positive:0.0||negative:0.0||entity:Boeing||general_negative:0.0||inherited_locations:Ohio,California,Huntington Beach||general_positive:0.0||document_category:Disaster_Accident"
GP7pV6ABCxs,0.075499758726,0.0,0.0,B_Ggm,EntityOccurrence,JPugEC,2012-08-16T02:03:38.000Z,2012-08-16T02:03:40.260Z,2012-08-15T00:00:00.000Z,2012-08-15T23:59:59.000Z,http://feeds.bizjournals.com/~r/vertical_30/~3/h2SDu6QnxXE/hypersonic-boeing-waverider-fails.html,Hypersonic Boeing Waverider fails after six seconds,C11,Bizjournals.com,Niche,,United States of America,"Steve Wilhelm Staff Writer- Puget Sound Business Journal Email The Boeing-built hypersonic Waverider, which was to have traveled at six times the speed of sound, failed in a test Wednesday.",positive:0.0||negative:0.0||entity:Boeing||general_negative:0.0||general_positive:0.0||document_category:Disaster_Accident
....
}}}

This file is a csv file, with column headings at the top. It should be pretty straightforward to open this in Excel or read it in with R's read.csv() command or python's csv module. 

===Aggregate Query Output===
Some aggregate results will look something like this:

{{{
Entity,Time,Count,Attention.30min,Attention.24hr,Positive,Negative
B_Ggm,2012-08-15 14:30:00,12,0.00826446,0.00546794,0,0
B_Ggm,2012-08-17 18:00:00,18,0.01633394,0.01515646,0,0
B_Ggm,2012-08-17 21:30:00,2,0.00166667,0.01094924,0,0
B_Ggm,2012-08-15 18:00:00,2,0.00211864,0.00833403,0.11842105,0
B_Ggm,2012-08-15 22:30:00,18,0.01152369,0.01147241,0,0
B_Ggm,2012-08-16 08:00:00,24,0.11111111,0.01798082,0.01657197,0.00833333
B_Ggm,2012-08-16 11:00:00,6,0.00618557,0.01617757,0,0
B_Ggm,2012-08-17 07:00:00,12,0.09090909,0.01232548,0.00824176,0
B_Ggm,2012-08-16 17:30:00,12,0.00957702,0.01085096,0,0
...
}}}

The columns here are the entity id, time stamp for the aggregate, count of articles referencing the entity associated with the ticker, the 30 minute and 24-hour attention, and average sentiment associated with the entity on that date. These results are also in CSV format, again easily ingestible by your favorite statistics software.

== Modify the queries ==

Users will likely want to try running their own queries, and the neat thing about the JSON query API is how flexible it is. You can query the data in the Recorded Future database from all sorts of directions. Changing dates and IDs really just scratches the surface. 

Before modifying these queries, we recommend reading [http://www.recordedfuture.com/api/home/ our API documentation]. There you will find what type of data you can ask for and what the various metadata fields in the results mean.